2018-08-30 15:00:12,240  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 15:00:12,243  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 15:00:14,912  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 15:00:14,996  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 15:00:15,306  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 3
2018-08-30 15:00:15,976  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:3
2018-08-30 15:00:16,747  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local991453483_0001
2018-08-30 15:00:17,041  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/usr/local/hadoopdata/tmp/mapred/staging/Administrator991453483/.staging/job_local991453483_0001
2018-08-30 15:02:16,697  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 15:02:16,699  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 15:02:18,424  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 15:02:18,521  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 15:02:18,790  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 3
2018-08-30 15:02:19,307  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:3
2018-08-30 15:02:19,709  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local2104659454_0001
2018-08-30 15:02:20,239  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 15:02:20,240  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local2104659454_0001
2018-08-30 15:02:20,268  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 15:02:20,282  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:02:20,285  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 15:02:20,428  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 15:02:20,430  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2104659454_0001_m_000000_0
2018-08-30 15:02:20,570  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:02:20,590  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:02:20,658  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ba7d61
2018-08-30 15:02:20,668  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/subjectScore/chinese:0+88
2018-08-30 15:02:20,964  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 15:02:20,964  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 15:02:20,964  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 15:02:20,964  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 15:02:20,965  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 15:02:20,970  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 15:02:20,995  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 15:02:20,996  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 15:02:20,996  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 15:02:20,996  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 160; bufvoid = 104857600
2018-08-30 15:02:20,996  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2018-08-30 15:02:21,103  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 15:02:21,128  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2104659454_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 15:02:21,140  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 15:02:21,140  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2104659454_0001_m_000000_0' done.
2018-08-30 15:02:21,140  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2104659454_0001_m_000000_0
2018-08-30 15:02:21,140  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2104659454_0001_m_000001_0
2018-08-30 15:02:21,141  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:02:21,142  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:02:21,248  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18288f2
2018-08-30 15:02:21,253  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/subjectScore/english:0+88
2018-08-30 15:02:21,304  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local2104659454_0001 running in uber mode : false
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 15:02:21,320  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 15:02:21,322  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 15:02:21,325  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 15:02:21,325  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 15:02:21,325  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 15:02:21,326  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 160; bufvoid = 104857600
2018-08-30 15:02:21,326  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2018-08-30 15:02:21,364  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 15:02:21,370  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2104659454_0001_m_000001_0 is done. And is in the process of committing
2018-08-30 15:02:21,372  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 15:02:21,373  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2104659454_0001_m_000001_0' done.
2018-08-30 15:02:21,373  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2104659454_0001_m_000001_0
2018-08-30 15:02:21,373  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2104659454_0001_m_000002_0
2018-08-30 15:02:21,374  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:02:21,375  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:02:21,448  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9a90b9
2018-08-30 15:02:21,452  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/subjectScore/math:0+88
2018-08-30 15:02:21,519  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 15:02:21,519  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 15:02:21,519  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 15:02:21,520  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 15:02:21,520  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 15:02:21,521  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 15:02:21,524  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 15:02:21,525  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 15:02:21,525  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 15:02:21,525  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 130; bufvoid = 104857600
2018-08-30 15:02:21,525  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2018-08-30 15:02:21,547  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 15:02:21,559  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2104659454_0001_m_000002_0 is done. And is in the process of committing
2018-08-30 15:02:21,562  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 15:02:21,563  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2104659454_0001_m_000002_0' done.
2018-08-30 15:02:21,563  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2104659454_0001_m_000002_0
2018-08-30 15:02:21,563  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 15:02:21,603  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 15:02:21,603  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2104659454_0001_r_000000_0
2018-08-30 15:02:21,621  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:02:21,621  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:02:21,729  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1cc5d5a
2018-08-30 15:02:21,746  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f45632
2018-08-30 15:02:21,787  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 15:02:21,795  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local2104659454_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 15:02:21,863  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local2104659454_0001_m_000000_0 decomp: 182 len: 186 to MEMORY
2018-08-30 15:02:21,889  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 182 bytes from map-output for attempt_local2104659454_0001_m_000000_0
2018-08-30 15:02:21,901  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 182, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->182
2018-08-30 15:02:21,907  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local2104659454_0001_m_000001_0 decomp: 182 len: 186 to MEMORY
2018-08-30 15:02:21,908  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 182 bytes from map-output for attempt_local2104659454_0001_m_000001_0
2018-08-30 15:02:21,908  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 182, inMemoryMapOutputs.size() -> 2, commitMemory -> 182, usedMemory ->364
2018-08-30 15:02:21,914  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local2104659454_0001_m_000002_0 decomp: 152 len: 156 to MEMORY
2018-08-30 15:02:21,915  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 152 bytes from map-output for attempt_local2104659454_0001_m_000002_0
2018-08-30 15:02:21,915  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 152, inMemoryMapOutputs.size() -> 3, commitMemory -> 364, usedMemory ->516
2018-08-30 15:02:21,915  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 15:02:21,918  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 3 / 3 copied.
2018-08-30 15:02:21,918  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 15:02:21,968  INFO [org.apache.hadoop.mapred.Merger] - Merging 3 sorted segments
2018-08-30 15:02:21,969  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 3 segments left of total size: 489 bytes
2018-08-30 15:02:21,974  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 3 segments, 516 bytes to disk to satisfy reduce memory limit
2018-08-30 15:02:21,975  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 516 bytes from disk
2018-08-30 15:02:21,976  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 15:02:21,976  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 15:02:21,977  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 502 bytes
2018-08-30 15:02:21,978  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 3 / 3 copied.
2018-08-30 15:02:22,158  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 15:02:22,179  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2104659454_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 15:02:22,180  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 3 / 3 copied.
2018-08-30 15:02:22,180  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local2104659454_0001_r_000000_0 is allowed to commit now
2018-08-30 15:02:22,183  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local2104659454_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/subjectScoreout/_temporary/0/task_local2104659454_0001_r_000000
2018-08-30 15:02:22,188  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 15:02:22,188  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2104659454_0001_r_000000_0' done.
2018-08-30 15:02:22,189  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2104659454_0001_r_000000_0
2018-08-30 15:02:22,189  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 15:02:22,325  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 15:02:23,326  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local2104659454_0001 completed successfully
2018-08-30 15:02:23,341  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=5456
		FILE: Number of bytes written=1173818
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=30
		Map output records=30
		Map output bytes=450
		Map output materialized bytes=528
		Input split bytes=345
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=528
		Reduce input records=30
		Reduce output records=3
		Spilled Records=60
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=175
		Total committed heap usage (bytes)=743055360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=264
	File Output Format Counters 
		Bytes Written=48
2018-08-30 15:07:55,227  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 15:07:55,229  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 15:07:56,942  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 15:07:57,025  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 15:07:57,302  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 3
2018-08-30 15:07:57,926  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:3
2018-08-30 15:07:58,303  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local92292453_0001
2018-08-30 15:07:58,412  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Cleaning up the staging area file:/usr/local/hadoopdata/tmp/mapred/staging/Administrator92292453/.staging/job_local92292453_0001
2018-08-30 15:38:31,870  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 15:38:31,873  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 15:38:33,677  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 15:38:33,760  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 15:38:33,829  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 15:38:34,309  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 15:38:34,738  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1281914888_0001
2018-08-30 15:38:35,181  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 15:38:35,182  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1281914888_0001
2018-08-30 15:38:35,184  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 15:38:35,189  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:35,191  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 15:38:35,243  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 15:38:35,244  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1281914888_0001_m_000000_0
2018-08-30 15:38:35,303  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:35,311  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:38:35,405  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b7cdc6
2018-08-30 15:38:35,421  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 15:38:35,548  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 15:38:35,549  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 15:38:35,549  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 15:38:35,549  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 15:38:35,549  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 15:38:35,557  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 15:38:35,570  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 15:38:35,570  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 15:38:35,570  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 15:38:35,570  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 130; bufvoid = 104857600
2018-08-30 15:38:35,571  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 15:38:35,602  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 15:38:35,639  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1281914888_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 15:38:35,653  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 15:38:35,653  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1281914888_0001_m_000000_0' done.
2018-08-30 15:38:35,653  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1281914888_0001_m_000000_0
2018-08-30 15:38:35,653  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 15:38:35,655  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 15:38:35,656  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1281914888_0001_r_000000_0
2018-08-30 15:38:35,670  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:35,671  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:38:35,762  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@8f8391
2018-08-30 15:38:35,767  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@130e714
2018-08-30 15:38:35,791  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 15:38:35,794  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1281914888_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 15:38:35,860  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1281914888_0001_m_000000_0 decomp: 162 len: 166 to MEMORY
2018-08-30 15:38:35,872  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 162 bytes from map-output for attempt_local1281914888_0001_m_000000_0
2018-08-30 15:38:35,875  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 162, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->162
2018-08-30 15:38:35,878  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 15:38:35,879  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:38:35,880  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 15:38:35,921  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 15:38:35,922  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 15:38:35,933  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 162 bytes to disk to satisfy reduce memory limit
2018-08-30 15:38:35,934  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 166 bytes from disk
2018-08-30 15:38:35,936  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 15:38:35,936  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 15:38:35,939  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 15:38:35,939  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:38:36,158  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 15:38:36,168  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:36,185  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1281914888_0001 running in uber mode : false
2018-08-30 15:38:36,187  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 15:38:36,341  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:36,543  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:36,703  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:38:36,880  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1281914888_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 15:38:36,882  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:38:36,882  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1281914888_0001_r_000000_0 is allowed to commit now
2018-08-30 15:38:36,953  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:38:36,954  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:38:36,954  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:38:36,954  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:38:36,955  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:38:36,955  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:38:36,956  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:38:36,956  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:38:36,957  WARN [org.apache.hadoop.mapred.Task] - Failure committing: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1281914888_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1281914888_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

2018-08-30 15:38:36,960  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:38:36,960  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:38:36,961  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:38:36,961  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:38:36,962  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:38:36,962  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:38:36,963  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:38:36,963  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:38:36,964  WARN [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Could not delete file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1281914888_0001_r_000000_0
2018-08-30 15:38:36,964  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 15:38:36,988  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:38:36,989  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:38:36,989  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:38:36,990  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:38:36,990  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:38:36,991  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:38:36,991  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:38:36,991  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1281914888_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:38:36,992  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1281914888_0001
java.lang.Exception: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1281914888_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1281914888_0001_r_000000
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1281914888_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1281914888_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 15:38:37,190  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1281914888_0001 failed with state FAILED due to: NA
2018-08-30 15:38:37,210  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=922
		FILE: Number of bytes written=597518
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=130
		Map output materialized bytes=166
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=166
		Reduce input records=15
		Reduce output records=0
		Spilled Records=30
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=56
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=8
2018-08-30 15:42:13,990  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 15:42:13,990  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 15:42:14,923  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 15:42:14,970  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 15:42:15,029  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 15:42:15,445  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 15:42:15,734  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1027368001_0001
2018-08-30 15:42:16,101  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 15:42:16,101  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1027368001_0001
2018-08-30 15:42:16,105  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 15:42:16,109  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:16,113  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 15:42:16,167  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 15:42:16,171  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1027368001_0001_m_000000_0
2018-08-30 15:42:16,198  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:16,202  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:42:16,296  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@f0d687
2018-08-30 15:42:16,304  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 15:42:16,398  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 15:42:16,398  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 15:42:16,398  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 15:42:16,398  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 15:42:16,398  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 15:42:16,402  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 15:42:16,417  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 15:42:16,417  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 15:42:16,417  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 15:42:16,417  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 130; bufvoid = 104857600
2018-08-30 15:42:16,417  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 15:42:16,445  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 15:42:16,452  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1027368001_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 15:42:16,464  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 15:42:16,464  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1027368001_0001_m_000000_0' done.
2018-08-30 15:42:16,464  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1027368001_0001_m_000000_0
2018-08-30 15:42:16,464  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 15:42:16,468  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 15:42:16,468  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1027368001_0001_r_000000_0
2018-08-30 15:42:16,476  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:16,480  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 15:42:16,550  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ccc078
2018-08-30 15:42:16,558  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f0d946
2018-08-30 15:42:16,574  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 15:42:16,577  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1027368001_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 15:42:16,628  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1027368001_0001_m_000000_0 decomp: 162 len: 166 to MEMORY
2018-08-30 15:42:16,632  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 162 bytes from map-output for attempt_local1027368001_0001_m_000000_0
2018-08-30 15:42:16,636  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 162, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->162
2018-08-30 15:42:16,636  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 15:42:16,640  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:42:16,640  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 15:42:16,652  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 15:42:16,656  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 15:42:16,656  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 162 bytes to disk to satisfy reduce memory limit
2018-08-30 15:42:16,659  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 166 bytes from disk
2018-08-30 15:42:16,659  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 15:42:16,659  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 15:42:16,663  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 15:42:16,663  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:42:16,816  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 15:42:16,824  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:16,995  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:17,105  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1027368001_0001 running in uber mode : false
2018-08-30 15:42:17,105  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 15:42:17,117  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:17,261  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 15:42:17,398  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1027368001_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 15:42:17,398  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 15:42:17,402  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1027368001_0001_r_000000_0 is allowed to commit now
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:42:17,445  WARN [org.apache.hadoop.mapred.Task] - Failure committing: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1027368001_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1027368001_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

2018-08-30 15:42:17,449  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:42:17,449  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:42:17,449  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:42:17,449  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:42:17,453  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:42:17,453  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:42:17,453  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:42:17,453  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:42:17,453  WARN [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Could not delete file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1027368001_0001_r_000000_0
2018-08-30 15:42:17,453  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1027368001_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 15:42:17,468  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1027368001_0001
java.lang.Exception: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1027368001_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1027368001_0001_r_000000
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1027368001_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1027368001_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 15:42:18,105  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1027368001_0001 failed with state FAILED due to: NA
2018-08-30 15:42:18,117  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=922
		FILE: Number of bytes written=597518
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=130
		Map output materialized bytes=166
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=166
		Reduce input records=15
		Reduce output records=0
		Spilled Records=30
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=8
2018-08-30 16:11:04,632  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:11:04,634  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:11:05,829  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:11:06,065  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:11:06,191  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:11:06,837  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:11:07,132  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local630448976_0001
2018-08-30 16:11:07,617  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:11:07,618  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local630448976_0001
2018-08-30 16:11:07,619  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:11:07,628  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:07,631  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:11:07,730  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:11:07,731  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local630448976_0001_m_000000_0
2018-08-30 16:11:07,775  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:07,782  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:11:07,844  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34f625
2018-08-30 16:11:07,851  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:11:07,972  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:11:07,973  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:11:07,973  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:11:07,973  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:11:07,973  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:11:07,979  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:11:07,992  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:11:07,992  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:11:07,992  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:11:07,993  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 130; bufvoid = 104857600
2018-08-30 16:11:07,993  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:11:08,022  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:11:08,031  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local630448976_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:11:08,044  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:11:08,045  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local630448976_0001_m_000000_0' done.
2018-08-30 16:11:08,045  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local630448976_0001_m_000000_0
2018-08-30 16:11:08,045  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:11:08,049  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:11:08,049  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local630448976_0001_r_000000_0
2018-08-30 16:11:08,061  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:08,062  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:11:08,180  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f0a8b0
2018-08-30 16:11:08,185  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5ea8af
2018-08-30 16:11:08,213  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:11:08,217  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local630448976_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:11:08,349  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local630448976_0001_m_000000_0 decomp: 162 len: 166 to MEMORY
2018-08-30 16:11:08,358  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 162 bytes from map-output for attempt_local630448976_0001_m_000000_0
2018-08-30 16:11:08,360  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 162, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->162
2018-08-30 16:11:08,362  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:11:08,363  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:11:08,364  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:11:08,385  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:11:08,385  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 16:11:08,389  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 162 bytes to disk to satisfy reduce memory limit
2018-08-30 16:11:08,390  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 166 bytes from disk
2018-08-30 16:11:08,392  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:11:08,393  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:11:08,394  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 16:11:08,396  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:11:08,601  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:11:08,612  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:08,623  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local630448976_0001 running in uber mode : false
2018-08-30 16:11:08,625  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 16:11:08,817  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:09,049  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:09,245  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:11:09,440  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local630448976_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:11:09,442  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:11:09,442  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local630448976_0001_r_000000_0 is allowed to commit now
2018-08-30 16:11:09,444  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local630448976_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local630448976_0001_r_000000
2018-08-30 16:11:09,445  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:11:09,445  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local630448976_0001_r_000000_0' done.
2018-08-30 16:11:09,446  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local630448976_0001_r_000000_0
2018-08-30 16:11:09,446  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:11:09,628  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 16:11:10,629  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local630448976_0001 completed successfully
2018-08-30 16:11:10,643  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=922
		FILE: Number of bytes written=594601
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=130
		Map output materialized bytes=166
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=166
		Reduce input records=15
		Reduce output records=0
		Spilled Records=30
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=48
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=8
2018-08-30 16:13:16,782  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:13:16,784  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:13:18,674  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:13:18,767  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:13:18,857  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:13:19,364  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:13:19,711  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1756380989_0001
2018-08-30 16:13:20,092  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:13:20,092  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1756380989_0001
2018-08-30 16:13:20,126  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:13:20,135  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:20,138  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:13:20,211  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:13:20,212  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1756380989_0001_m_000000_0
2018-08-30 16:13:20,242  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:20,250  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:13:20,323  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f5a5b
2018-08-30 16:13:20,340  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:13:20,477  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:13:20,477  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:13:20,478  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:13:20,478  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:13:20,478  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:13:20,481  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:13:20,492  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:13:20,493  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:13:20,493  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:13:20,493  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 130; bufvoid = 104857600
2018-08-30 16:13:20,493  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:13:20,522  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:13:20,532  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1756380989_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:13:20,551  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:13:20,551  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1756380989_0001_m_000000_0' done.
2018-08-30 16:13:20,551  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1756380989_0001_m_000000_0
2018-08-30 16:13:20,551  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:13:20,554  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:13:20,555  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1756380989_0001_r_000000_0
2018-08-30 16:13:20,573  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:20,574  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:13:20,689  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13e07bd
2018-08-30 16:13:20,695  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@193f119
2018-08-30 16:13:20,715  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:13:20,719  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1756380989_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:13:20,797  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1756380989_0001_m_000000_0 decomp: 162 len: 166 to MEMORY
2018-08-30 16:13:20,811  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 162 bytes from map-output for attempt_local1756380989_0001_m_000000_0
2018-08-30 16:13:20,814  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 162, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->162
2018-08-30 16:13:20,821  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:13:20,822  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:13:20,822  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:13:20,846  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:13:20,847  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 16:13:20,850  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 162 bytes to disk to satisfy reduce memory limit
2018-08-30 16:13:20,854  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 166 bytes from disk
2018-08-30 16:13:20,858  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:13:20,859  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:13:20,860  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2018-08-30 16:13:20,862  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:13:21,039  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:13:21,055  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:21,111  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1756380989_0001 running in uber mode : false
2018-08-30 16:13:21,113  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 16:13:21,263  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:21,478  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:21,687  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:13:21,885  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1756380989_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:13:21,887  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:13:21,887  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1756380989_0001_r_000000_0 is allowed to commit now
2018-08-30 16:13:21,949  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 16:13:21,950  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 16:13:21,950  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 16:13:21,951  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 16:13:21,952  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 16:13:21,952  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 16:13:21,953  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 16:13:21,953  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 16:13:21,954  WARN [org.apache.hadoop.mapred.Task] - Failure committing: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1756380989_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1756380989_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

2018-08-30 16:13:21,957  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 16:13:21,959  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 16:13:21,959  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 16:13:21,960  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 16:13:21,960  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 16:13:21,961  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 16:13:21,961  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 16:13:21,962  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 16:13:21,985  WARN [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Could not delete file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1756380989_0001_r_000000_0
2018-08-30 16:13:21,986  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:13:22,005  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.09-r-00000.crc]: it still exists.
2018-08-30 16:13:22,005  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.AB-r-00000.crc]: it still exists.
2018-08-30 16:13:22,006  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.az-r-00000.crc]: it still exists.
2018-08-30 16:13:22,007  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\.others-r-00000.crc]: it still exists.
2018-08-30 16:13:22,008  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\09-r-00000]: it still exists.
2018-08-30 16:13:22,009  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\AB-r-00000]: it still exists.
2018-08-30 16:13:22,009  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\az-r-00000]: it still exists.
2018-08-30 16:13:22,009  WARN [org.apache.hadoop.fs.FileUtil] - Failed to delete file or dir [F:\Data\GP1809\wordcount\multiFilesout\_temporary\0\_temporary\attempt_local1756380989_0001_r_000000_0\others-r-00000]: it still exists.
2018-08-30 16:13:22,011  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1756380989_0001
java.lang.Exception: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1756380989_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1756380989_0001_r_000000
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.io.IOException: Could not rename file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/_temporary/attempt_local1756380989_0001_r_000000_0 to file:/F:/Data/GP1809/wordcount/multiFilesout/_temporary/0/task_local1756380989_0001_r_000000
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:479)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:449)
	at org.apache.hadoop.mapred.Task.commit(Task.java:1200)
	at org.apache.hadoop.mapred.Task.done(Task.java:1062)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:397)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 16:13:22,115  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1756380989_0001 failed with state FAILED due to: NA
2018-08-30 16:13:22,129  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=922
		FILE: Number of bytes written=597518
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=130
		Map output materialized bytes=166
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=166
		Reduce input records=15
		Reduce output records=0
		Spilled Records=30
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=8
2018-08-30 16:36:49,903  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:36:49,905  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:36:51,411  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:36:51,542  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:36:51,941  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:36:52,494  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:36:52,900  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1800701187_0001
2018-08-30 16:36:53,337  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:36:53,338  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1800701187_0001
2018-08-30 16:36:53,341  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:36:53,352  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:36:53,353  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:36:53,455  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:36:53,456  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1800701187_0001_m_000000_0
2018-08-30 16:36:53,534  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:36:53,554  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:36:53,665  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@129271e
2018-08-30 16:36:53,689  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:36:53,815  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:36:53,815  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:36:53,816  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:36:53,816  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:36:53,816  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:36:53,821  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:36:53,832  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:36:53,888  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:36:53,892  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1800701187_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1079)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:63)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:30)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 16:36:54,341  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1800701187_0001 running in uber mode : false
2018-08-30 16:36:54,343  INFO [org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
2018-08-30 16:36:54,348  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1800701187_0001 failed with state FAILED due to: NA
2018-08-30 16:36:54,356  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 0
2018-08-30 16:37:41,503  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:37:41,506  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:37:43,267  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:37:43,355  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:37:43,459  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:37:43,983  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:37:44,335  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1404273797_0001
2018-08-30 16:37:44,698  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:37:44,700  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1404273797_0001
2018-08-30 16:37:44,700  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:37:44,708  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:37:44,710  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:37:44,776  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:37:44,776  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1404273797_0001_m_000000_0
2018-08-30 16:37:44,808  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:37:44,818  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:37:44,903  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1e2b2a6
2018-08-30 16:37:44,911  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:37:45,043  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:37:45,044  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:37:45,044  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:37:45,044  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:37:45,044  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:37:45,050  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:37:45,061  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:37:45,061  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:37:45,061  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:37:45,061  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 160; bufvoid = 104857600
2018-08-30 16:37:45,061  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:37:45,086  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:37:45,097  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1404273797_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:37:45,109  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:37:45,109  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1404273797_0001_m_000000_0' done.
2018-08-30 16:37:45,109  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1404273797_0001_m_000000_0
2018-08-30 16:37:45,110  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:37:45,114  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:37:45,115  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1404273797_0001_r_000000_0
2018-08-30 16:37:45,130  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:37:45,133  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:37:45,261  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1156187
2018-08-30 16:37:45,266  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a4505
2018-08-30 16:37:45,290  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:37:45,295  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1404273797_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:37:45,369  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1404273797_0001_m_000000_0 decomp: 192 len: 196 to MEMORY
2018-08-30 16:37:45,377  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 192 bytes from map-output for attempt_local1404273797_0001_m_000000_0
2018-08-30 16:37:45,382  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 192, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192
2018-08-30 16:37:45,384  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:37:45,385  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:37:45,385  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:37:45,407  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:37:45,408  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2018-08-30 16:37:45,413  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 192 bytes to disk to satisfy reduce memory limit
2018-08-30 16:37:45,415  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 196 bytes from disk
2018-08-30 16:37:45,417  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:37:45,417  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:37:45,418  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 185 bytes
2018-08-30 16:37:45,419  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:37:45,643  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:37:45,655  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1404273797_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:37:45,657  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:37:45,657  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1404273797_0001_r_000000_0 is allowed to commit now
2018-08-30 16:37:45,660  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1404273797_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local1404273797_0001_r_000000
2018-08-30 16:37:45,661  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:37:45,661  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1404273797_0001_r_000000_0' done.
2018-08-30 16:37:45,662  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1404273797_0001_r_000000_0
2018-08-30 16:37:45,663  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:37:45,710  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1404273797_0001 running in uber mode : false
2018-08-30 16:37:45,713  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 16:37:46,715  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1404273797_0001 completed successfully
2018-08-30 16:37:46,725  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=982
		FILE: Number of bytes written=586866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=160
		Map output materialized bytes=196
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=196
		Reduce input records=15
		Reduce output records=14
		Spilled Records=30
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=58
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=134
2018-08-30 16:39:25,511  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:39:25,514  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:39:27,277  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:39:27,358  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:39:27,459  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:39:28,078  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:39:28,464  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local730016501_0001
2018-08-30 16:39:28,839  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:39:28,840  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local730016501_0001
2018-08-30 16:39:28,842  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:39:28,849  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:39:28,851  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:39:28,925  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:39:28,925  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local730016501_0001_m_000000_0
2018-08-30 16:39:28,966  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:39:28,973  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:39:29,051  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c73ac2
2018-08-30 16:39:29,067  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:39:29,189  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:39:29,189  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:39:29,189  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:39:29,190  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:39:29,190  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:39:29,195  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:39:29,205  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:39:29,232  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:39:29,235  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local730016501_0001
java.lang.Exception: java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to javax.xml.soap.Text
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to javax.xml.soap.Text
	at com.qfedu.bigdata.mr.day14.MyPartitionerDemo.getPartition(MyPartitionerDemo.java:24)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:716)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:63)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:30)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 16:39:29,842  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local730016501_0001 running in uber mode : false
2018-08-30 16:39:29,844  INFO [org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
2018-08-30 16:39:29,847  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local730016501_0001 failed with state FAILED due to: NA
2018-08-30 16:39:29,853  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 0
2018-08-30 16:41:29,707  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:41:29,711  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:41:31,615  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:41:31,684  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:41:31,784  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:41:32,287  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:41:32,645  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1578225736_0001
2018-08-30 16:41:33,065  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:41:33,066  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1578225736_0001
2018-08-30 16:41:33,068  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:41:33,100  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:41:33,103  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:41:33,228  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:41:33,230  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1578225736_0001_m_000000_0
2018-08-30 16:41:33,264  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:41:33,271  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:41:33,346  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@10c266e
2018-08-30 16:41:33,355  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:41:33,478  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:41:33,478  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:41:33,478  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:41:33,478  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:41:33,478  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:41:33,483  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:41:33,492  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:41:33,553  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:41:33,555  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1578225736_0001
java.lang.Exception: java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to javax.xml.soap.Text
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to javax.xml.soap.Text
	at com.qfedu.bigdata.mr.day14.MyPartitionerDemo.getPartition(MyPartitionerDemo.java:24)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:716)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:60)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:27)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 16:41:34,069  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1578225736_0001 running in uber mode : false
2018-08-30 16:41:34,070  INFO [org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
2018-08-30 16:41:34,072  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1578225736_0001 failed with state FAILED due to: NA
2018-08-30 16:41:34,080  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 0
2018-08-30 16:42:52,929  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:42:52,931  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:42:54,607  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:42:54,689  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:42:54,787  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:42:55,315  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:42:55,761  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1978402179_0001
2018-08-30 16:42:56,182  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:42:56,183  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1978402179_0001
2018-08-30 16:42:56,184  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:42:56,188  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:56,190  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:42:56,269  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:42:56,269  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:56,296  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:56,306  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:42:56,371  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34ca1a
2018-08-30 16:42:56,379  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:42:56,522  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:42:56,522  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:42:56,522  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:42:56,522  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:42:56,522  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:42:56,542  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:42:56,555  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:42:56,556  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:42:56,556  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:42:56,556  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 160; bufvoid = 104857600
2018-08-30 16:42:56,556  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:42:56,597  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:42:56,611  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1978402179_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:42:56,622  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:42:56,622  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1978402179_0001_m_000000_0' done.
2018-08-30 16:42:56,622  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:56,622  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:42:56,627  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:42:56,627  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1978402179_0001_r_000000_0
2018-08-30 16:42:56,643  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:56,645  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:42:56,749  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@55acbc
2018-08-30 16:42:56,755  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4d5e50
2018-08-30 16:42:56,787  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:42:56,794  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1978402179_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:42:56,878  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local1978402179_0001_m_000000_0 decomp: 50 len: 54 to MEMORY
2018-08-30 16:42:56,885  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 50 bytes from map-output for attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:56,887  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2018-08-30 16:42:56,889  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:42:56,890  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:56,891  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:42:56,946  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:56,946  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2018-08-30 16:42:56,949  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2018-08-30 16:42:56,950  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 54 bytes from disk
2018-08-30 16:42:56,952  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:42:56,952  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:56,953  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2018-08-30 16:42:56,954  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,184  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1978402179_0001 running in uber mode : false
2018-08-30 16:42:57,187  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 16:42:57,190  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:42:57,200  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1978402179_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:42:57,202  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,202  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1978402179_0001_r_000000_0 is allowed to commit now
2018-08-30 16:42:57,204  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1978402179_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local1978402179_0001_r_000000
2018-08-30 16:42:57,205  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:42:57,205  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1978402179_0001_r_000000_0' done.
2018-08-30 16:42:57,205  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1978402179_0001_r_000000_0
2018-08-30 16:42:57,205  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1978402179_0001_r_000001_0
2018-08-30 16:42:57,207  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:57,207  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:42:57,298  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@126c1c6
2018-08-30 16:42:57,298  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@17bd8d0
2018-08-30 16:42:57,300  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:42:57,305  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1978402179_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:42:57,311  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#2 about to shuffle output of map attempt_local1978402179_0001_m_000000_0 decomp: 82 len: 86 to MEMORY
2018-08-30 16:42:57,312  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 82 bytes from map-output for attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:57,312  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82
2018-08-30 16:42:57,313  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:42:57,314  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,314  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:42:57,326  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:57,326  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 68 bytes
2018-08-30 16:42:57,336  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit
2018-08-30 16:42:57,337  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 86 bytes from disk
2018-08-30 16:42:57,338  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:42:57,338  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:57,339  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 68 bytes
2018-08-30 16:42:57,339  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,548  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1978402179_0001_r_000001_0 is done. And is in the process of committing
2018-08-30 16:42:57,550  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,550  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1978402179_0001_r_000001_0 is allowed to commit now
2018-08-30 16:42:57,553  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1978402179_0001_r_000001_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local1978402179_0001_r_000001
2018-08-30 16:42:57,554  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:42:57,554  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1978402179_0001_r_000001_0' done.
2018-08-30 16:42:57,554  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1978402179_0001_r_000001_0
2018-08-30 16:42:57,554  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1978402179_0001_r_000002_0
2018-08-30 16:42:57,556  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:57,556  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:42:57,651  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1de56e2
2018-08-30 16:42:57,651  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a323d
2018-08-30 16:42:57,654  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:42:57,658  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1978402179_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:42:57,663  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#3 about to shuffle output of map attempt_local1978402179_0001_m_000000_0 decomp: 35 len: 39 to MEMORY
2018-08-30 16:42:57,663  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 35 bytes from map-output for attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:57,664  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 35, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->35
2018-08-30 16:42:57,665  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:42:57,665  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,665  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:42:57,701  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:57,701  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 27 bytes
2018-08-30 16:42:57,703  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 35 bytes to disk to satisfy reduce memory limit
2018-08-30 16:42:57,704  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 39 bytes from disk
2018-08-30 16:42:57,704  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:42:57,704  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:57,705  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 27 bytes
2018-08-30 16:42:57,706  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,903  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1978402179_0001_r_000002_0 is done. And is in the process of committing
2018-08-30 16:42:57,906  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:57,906  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1978402179_0001_r_000002_0 is allowed to commit now
2018-08-30 16:42:57,911  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1978402179_0001_r_000002_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local1978402179_0001_r_000002
2018-08-30 16:42:57,912  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:42:57,913  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1978402179_0001_r_000002_0' done.
2018-08-30 16:42:57,913  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1978402179_0001_r_000002_0
2018-08-30 16:42:57,913  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1978402179_0001_r_000003_0
2018-08-30 16:42:57,914  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:42:57,915  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:42:58,002  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9198ea
2018-08-30 16:42:58,002  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ce3c61
2018-08-30 16:42:58,004  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:42:58,007  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local1978402179_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:42:58,011  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#4 about to shuffle output of map attempt_local1978402179_0001_m_000000_0 decomp: 31 len: 35 to MEMORY
2018-08-30 16:42:58,012  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 31 bytes from map-output for attempt_local1978402179_0001_m_000000_0
2018-08-30 16:42:58,012  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2018-08-30 16:42:58,017  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:42:58,018  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:58,018  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:42:58,052  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:58,053  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 20 bytes
2018-08-30 16:42:58,055  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 31 bytes to disk to satisfy reduce memory limit
2018-08-30 16:42:58,056  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 35 bytes from disk
2018-08-30 16:42:58,056  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:42:58,056  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:42:58,058  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 20 bytes
2018-08-30 16:42:58,060  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:58,196  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 75%
2018-08-30 16:42:58,283  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local1978402179_0001_r_000003_0 is done. And is in the process of committing
2018-08-30 16:42:58,286  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:42:58,287  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local1978402179_0001_r_000003_0 is allowed to commit now
2018-08-30 16:42:58,300  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local1978402179_0001_r_000003_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local1978402179_0001_r_000003
2018-08-30 16:42:58,301  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:42:58,301  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local1978402179_0001_r_000003_0' done.
2018-08-30 16:42:58,301  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local1978402179_0001_r_000003_0
2018-08-30 16:42:58,301  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:42:59,198  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 16:42:59,199  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1978402179_0001 completed successfully
2018-08-30 16:42:59,241  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=4541
		FILE: Number of bytes written=1467802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=160
		Map output materialized bytes=214
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=214
		Reduce input records=15
		Reduce output records=14
		Spilled Records=30
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=66
		Total committed heap usage (bytes)=605900800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=170
2018-08-30 16:44:04,958  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:44:04,963  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:44:06,291  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:44:06,342  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:44:06,511  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:44:07,239  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:44:07,649  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local2146405611_0001
2018-08-30 16:44:08,063  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:44:08,065  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local2146405611_0001
2018-08-30 16:44:08,067  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:44:08,076  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:08,079  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:44:08,151  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:44:08,152  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2146405611_0001_m_000000_0
2018-08-30 16:44:08,199  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:08,211  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:44:08,279  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3170cc
2018-08-30 16:44:08,287  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:44:08,418  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:44:08,418  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:44:08,418  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:44:08,418  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:44:08,418  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:44:08,423  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:44:08,437  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:44:08,438  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:44:08,438  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:44:08,440  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 160; bufvoid = 104857600
2018-08-30 16:44:08,440  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:44:08,470  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:44:08,484  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2146405611_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:44:08,501  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:44:08,502  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2146405611_0001_m_000000_0' done.
2018-08-30 16:44:08,502  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2146405611_0001_m_000000_0
2018-08-30 16:44:08,503  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:44:08,507  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:44:08,507  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2146405611_0001_r_000000_0
2018-08-30 16:44:08,522  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:08,526  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:44:08,642  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64e8ad
2018-08-30 16:44:08,646  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e05ace
2018-08-30 16:44:08,670  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:44:08,674  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local2146405611_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:44:08,761  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local2146405611_0001_m_000000_0 decomp: 83 len: 87 to MEMORY
2018-08-30 16:44:08,768  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 83 bytes from map-output for attempt_local2146405611_0001_m_000000_0
2018-08-30 16:44:08,770  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 83, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->83
2018-08-30 16:44:08,774  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:44:08,775  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:08,775  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:44:08,800  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:44:08,800  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 76 bytes
2018-08-30 16:44:08,803  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 83 bytes to disk to satisfy reduce memory limit
2018-08-30 16:44:08,804  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 87 bytes from disk
2018-08-30 16:44:08,806  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:44:08,807  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:44:08,808  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 76 bytes
2018-08-30 16:44:08,808  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:09,003  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:44:09,035  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2146405611_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:44:09,036  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:09,036  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local2146405611_0001_r_000000_0 is allowed to commit now
2018-08-30 16:44:09,040  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local2146405611_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local2146405611_0001_r_000000
2018-08-30 16:44:09,042  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:44:09,043  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2146405611_0001_r_000000_0' done.
2018-08-30 16:44:09,043  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2146405611_0001_r_000000_0
2018-08-30 16:44:09,043  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local2146405611_0001_r_000001_0
2018-08-30 16:44:09,044  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:09,045  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:44:09,082  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local2146405611_0001 running in uber mode : false
2018-08-30 16:44:09,094  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 16:44:09,155  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@204bcc
2018-08-30 16:44:09,155  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@504a73
2018-08-30 16:44:09,156  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:44:09,163  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local2146405611_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:44:09,168  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#2 about to shuffle output of map attempt_local2146405611_0001_m_000000_0 decomp: 111 len: 115 to MEMORY
2018-08-30 16:44:09,170  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 111 bytes from map-output for attempt_local2146405611_0001_m_000000_0
2018-08-30 16:44:09,170  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 111, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->111
2018-08-30 16:44:09,172  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:44:09,173  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:09,173  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:44:09,187  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:44:09,187  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 100 bytes
2018-08-30 16:44:09,191  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 111 bytes to disk to satisfy reduce memory limit
2018-08-30 16:44:09,192  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 115 bytes from disk
2018-08-30 16:44:09,192  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:44:09,192  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:44:09,193  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 100 bytes
2018-08-30 16:44:09,193  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:09,424  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local2146405611_0001_r_000001_0 is done. And is in the process of committing
2018-08-30 16:44:09,432  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:44:09,433  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local2146405611_0001_r_000001_0 is allowed to commit now
2018-08-30 16:44:09,436  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local2146405611_0001_r_000001_0' to file:/F:/Data/GP1809/wordcount/multiFilesout1/_temporary/0/task_local2146405611_0001_r_000001
2018-08-30 16:44:09,437  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:44:09,438  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local2146405611_0001_r_000001_0' done.
2018-08-30 16:44:09,438  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local2146405611_0001_r_000001_0
2018-08-30 16:44:09,438  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:44:10,097  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local2146405611_0001 completed successfully
2018-08-30 16:44:10,113  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=1813
		FILE: Number of bytes written=880376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=160
		Map output materialized bytes=202
		Input split bytes=116
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=202
		Reduce input records=15
		Reduce output records=14
		Spilled Records=30
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=60
		Total committed heap usage (bytes)=363540480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=146
2018-08-30 16:44:48,826  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:44:48,828  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:44:50,606  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:44:50,684  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:44:50,796  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:44:51,368  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:44:51,788  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local1892906697_0001
2018-08-30 16:44:52,173  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:44:52,174  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local1892906697_0001
2018-08-30 16:44:52,177  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:44:52,186  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:52,188  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:44:52,264  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:44:52,264  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local1892906697_0001_m_000000_0
2018-08-30 16:44:52,306  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:44:52,315  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:44:52,404  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@102ead5
2018-08-30 16:44:52,415  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:44:52,549  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:44:52,549  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:44:52,550  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:44:52,551  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:44:52,551  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:44:52,558  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:44:52,569  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:44:52,569  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:44:52,569  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 20; bufvoid = 104857600
2018-08-30 16:44:52,569  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-08-30 16:44:52,601  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:44:52,614  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:44:52,618  WARN [org.apache.hadoop.mapred.LocalJobRunner] - job_local1892906697_0001
java.lang.Exception: java.io.IOException: Illegal partition for Hello (2)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for Hello (2)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:60)
	at com.qfedu.bigdata.mr.day14.partitionerDemo$MyMapper.map(partitionerDemo.java:27)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-08-30 16:44:53,177  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1892906697_0001 running in uber mode : false
2018-08-30 16:44:53,178  INFO [org.apache.hadoop.mapreduce.Job] -  map 0% reduce 0%
2018-08-30 16:44:53,181  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local1892906697_0001 failed with state FAILED due to: NA
2018-08-30 16:44:53,185  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 0
2018-08-30 16:50:57,607  INFO [org.apache.hadoop.conf.Configuration.deprecation] - session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-30 16:50:57,611  INFO [org.apache.hadoop.metrics.jvm.JvmMetrics] - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-08-30 16:50:59,149  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-30 16:50:59,219  WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-30 16:50:59,300  INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 1
2018-08-30 16:50:59,797  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1
2018-08-30 16:51:00,197  INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_local992212807_0001
2018-08-30 16:51:00,624  INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://localhost:8080/
2018-08-30 16:51:00,626  INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_local992212807_0001
2018-08-30 16:51:00,628  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter set in config null
2018-08-30 16:51:00,635  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:51:00,637  INFO [org.apache.hadoop.mapred.LocalJobRunner] - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-30 16:51:00,784  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for map tasks
2018-08-30 16:51:00,784  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local992212807_0001_m_000000_0
2018-08-30 16:51:00,840  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:51:00,848  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:51:00,947  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1859d8c
2018-08-30 16:51:00,956  INFO [org.apache.hadoop.mapred.MapTask] - Processing split: file:/F:/Data/GP1809/wordcount/multiFiles/multiFile:0+109
2018-08-30 16:51:01,073  INFO [org.apache.hadoop.mapred.MapTask] - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-30 16:51:01,073  INFO [org.apache.hadoop.mapred.MapTask] - mapreduce.task.io.sort.mb: 100
2018-08-30 16:51:01,073  INFO [org.apache.hadoop.mapred.MapTask] - soft limit at 83886080
2018-08-30 16:51:01,074  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufvoid = 104857600
2018-08-30 16:51:01,074  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396; length = 6553600
2018-08-30 16:51:01,079  INFO [org.apache.hadoop.mapred.MapTask] - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-30 16:51:01,100  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 
2018-08-30 16:51:01,101  INFO [org.apache.hadoop.mapred.MapTask] - Starting flush of map output
2018-08-30 16:51:01,101  INFO [org.apache.hadoop.mapred.MapTask] - Spilling map output
2018-08-30 16:51:01,101  INFO [org.apache.hadoop.mapred.MapTask] - bufstart = 0; bufend = 220; bufvoid = 104857600
2018-08-30 16:51:01,101  INFO [org.apache.hadoop.mapred.MapTask] - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2018-08-30 16:51:01,182  INFO [org.apache.hadoop.mapred.MapTask] - Finished spill 0
2018-08-30 16:51:01,196  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local992212807_0001_m_000000_0 is done. And is in the process of committing
2018-08-30 16:51:01,217  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map
2018-08-30 16:51:01,217  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local992212807_0001_m_000000_0' done.
2018-08-30 16:51:01,217  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local992212807_0001_m_000000_0
2018-08-30 16:51:01,217  INFO [org.apache.hadoop.mapred.LocalJobRunner] - map task executor complete.
2018-08-30 16:51:01,221  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Waiting for reduce tasks
2018-08-30 16:51:01,226  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Starting task: attempt_local992212807_0001_r_000000_0
2018-08-30 16:51:01,239  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - File Output Committer Algorithm version is 1
2018-08-30 16:51:01,240  INFO [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree] - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-30 16:51:01,363  INFO [org.apache.hadoop.mapred.Task] -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13ff9d4
2018-08-30 16:51:01,372  INFO [org.apache.hadoop.mapred.ReduceTask] - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e5305e
2018-08-30 16:51:01,396  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - MergerManager: memoryLimit=181665792, maxSingleShuffleLimit=45416448, mergeThreshold=119899424, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-30 16:51:01,409  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - attempt_local992212807_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-30 16:51:01,473  INFO [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher] - localfetcher#1 about to shuffle output of map attempt_local992212807_0001_m_000000_0 decomp: 236 len: 240 to MEMORY
2018-08-30 16:51:01,477  INFO [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput] - Read 236 bytes from map-output for attempt_local992212807_0001_m_000000_0
2018-08-30 16:51:01,478  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - closeInMemoryFile -> map-output of size: 236, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->236
2018-08-30 16:51:01,479  INFO [org.apache.hadoop.mapreduce.task.reduce.EventFetcher] - EventFetcher is interrupted.. Returning
2018-08-30 16:51:01,480  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:51:01,481  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2018-08-30 16:51:01,505  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:51:01,506  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 229 bytes
2018-08-30 16:51:01,507  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merged 1 segments, 236 bytes to disk to satisfy reduce memory limit
2018-08-30 16:51:01,508  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 1 files, 240 bytes from disk
2018-08-30 16:51:01,509  INFO [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl] - Merging 0 segments, 0 bytes from memory into reduce
2018-08-30 16:51:01,510  INFO [org.apache.hadoop.mapred.Merger] - Merging 1 sorted segments
2018-08-30 16:51:01,510  INFO [org.apache.hadoop.mapred.Merger] - Down to the last merge-pass, with 1 segments left of total size: 229 bytes
2018-08-30 16:51:01,511  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:51:01,632  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local992212807_0001 running in uber mode : false
2018-08-30 16:51:01,634  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 0%
2018-08-30 16:51:01,747  INFO [org.apache.hadoop.conf.Configuration.deprecation] - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-30 16:51:01,751  INFO [org.apache.hadoop.mapred.Task] - Task:attempt_local992212807_0001_r_000000_0 is done. And is in the process of committing
2018-08-30 16:51:01,753  INFO [org.apache.hadoop.mapred.LocalJobRunner] - 1 / 1 copied.
2018-08-30 16:51:01,753  INFO [org.apache.hadoop.mapred.Task] - Task attempt_local992212807_0001_r_000000_0 is allowed to commit now
2018-08-30 16:51:01,756  INFO [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter] - Saved output of task 'attempt_local992212807_0001_r_000000_0' to file:/F:/Data/GP1809/wordcount/multiFilesout2/_temporary/0/task_local992212807_0001_r_000000
2018-08-30 16:51:01,756  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce > reduce
2018-08-30 16:51:01,757  INFO [org.apache.hadoop.mapred.Task] - Task 'attempt_local992212807_0001_r_000000_0' done.
2018-08-30 16:51:01,757  INFO [org.apache.hadoop.mapred.LocalJobRunner] - Finishing task: attempt_local992212807_0001_r_000000_0
2018-08-30 16:51:01,757  INFO [org.apache.hadoop.mapred.LocalJobRunner] - reduce task executor complete.
2018-08-30 16:51:02,637  INFO [org.apache.hadoop.mapreduce.Job] -  map 100% reduce 100%
2018-08-30 16:51:02,637  INFO [org.apache.hadoop.mapreduce.Job] - Job job_local992212807_0001 completed successfully
2018-08-30 16:51:02,653  INFO [org.apache.hadoop.mapreduce.Job] - Counters: 30
	File System Counters
		FILE: Number of bytes read=1070
		FILE: Number of bytes written=583930
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=15
		Map output bytes=220
		Map output materialized bytes=240
		Input split bytes=116
		Combine input records=15
		Combine output records=14
		Reduce input groups=14
		Reduce shuffle bytes=240
		Reduce input records=14
		Reduce output records=14
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=44
		Total committed heap usage (bytes)=242360320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=109
	File Output Format Counters 
		Bytes Written=134
